Claro! Vamos gerar o código para treinar um classificador SVM utilizando a representação **Bag-of-Words (BoW)**. Esse modelo usará a frequência de palavras nas avaliações pré-processadas para prever o sentimento associado.

### **Passos a Seguir**

1. **Carregar os dados pré-processados** do arquivo CSV resultante do pré-processamento.
2. **Dividir os dados** em conjuntos de treinamento e teste.
3. **Converter o texto em representações BoW** usando `CountVectorizer`.
4. **Treinar o classificador SVM** no conjunto de treinamento.
5. **Avaliar o modelo** no conjunto de teste usando métricas como acurácia e F1-score.
6. **Exibir os resultados**.

### **Código Completo**

```python
# Importar bibliotecas necessárias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Carregar os dados pré-processados
df = pd.read_csv('avaliacoes_preprocessadas.csv')

# Exibir as primeiras linhas do DataFrame
print("Dados pré-processados:")
print(df.head())

# Verificar se há valores nulos
print("\nVerificando valores nulos:")
print(df.isnull().sum())

# Remover linhas com valores nulos (se houver)
df.dropna(inplace=True)

# 2. Dividir os dados em conjuntos de treinamento e teste

# Separar as features (texto) e o target (sentimento)
X = df['clean_review']
y = df['sentiment']

# Dividir em treinamento e teste (80% treinamento, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 3. Converter o texto em representações BoW

# Inicializar o CountVectorizer
vectorizer = CountVectorizer()

# Ajustar e transformar os dados de treinamento
X_train_bow = vectorizer.fit_transform(X_train)

# Transformar os dados de teste
X_test_bow = vectorizer.transform(X_test)

# 4. Treinar o classificador SVM

# Inicializar o classificador SVM (usando kernel linear para velocidade)
svm_classifier = SVC(kernel='linear', random_state=42)

# Treinar o modelo
svm_classifier.fit(X_train_bow, y_train)

# 5. Avaliar o modelo no conjunto de teste

# Prever os sentimentos no conjunto de teste
y_pred = svm_classifier.predict(X_test_bow)

# Calcular a acurácia
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAcurácia no conjunto de teste: {accuracy:.4f}")

# Exibir o relatório de classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred, digits=4))

# Matriz de Confusão
conf_matrix = confusion_matrix(y_test, y_pred, labels=['positivo', 'neutro', 'negativo'])

# Visualizar a matriz de confusão
plt.figure(figsize=(8,6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Positivo', 'Neutro', 'Negativo'], yticklabels=['Positivo', 'Neutro', 'Negativo'])
plt.title('Matriz de Confusão')
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')
plt.show()
```

### **Explicação do Código**

#### **1. Carregar os dados pré-processados**

- **Leitura do arquivo CSV**: Carregamos o DataFrame a partir do arquivo `avaliacoes_preprocessadas.csv`.
- **Verificação de valores nulos**: Checamos se há valores nulos e os removemos se necessário.

#### **2. Dividir os dados em conjuntos de treinamento e teste**

- **Separação das features e target**:
  - `X`: Contém o texto pré-processado (`clean_review`).
  - `y`: Contém os rótulos de sentimento (`sentiment`).
- **Divisão dos dados**:
  - Usamos `train_test_split` para dividir os dados em treinamento e teste.
  - O parâmetro `stratify=y` garante que a proporção de classes seja mantida em ambos os conjuntos.
  - `random_state` é definido para reprodutibilidade.

#### **3. Converter o texto em representações BoW**

- **Inicialização do `CountVectorizer`**:
  - Converte o texto em uma matriz de frequências de palavras.
- **Ajuste e transformação dos dados de treinamento**:
  - `fit_transform` aprende o vocabulário e transforma o texto em vetores.
- **Transformação dos dados de teste**:
  - Usamos `transform` para converter o texto de teste com o vocabulário aprendido no conjunto de treinamento.

#### **4. Treinar o classificador SVM**

- **Inicialização do SVM**:
  - Usamos o kernel linear para simplificar o modelo e acelerar o treinamento.
- **Treinamento do modelo**:
  - O método `fit` treina o modelo nos dados de treinamento.

#### **5. Avaliar o modelo no conjunto de teste**

- **Predição no conjunto de teste**:
  - Usamos o modelo treinado para prever os sentimentos das avaliações de teste.
- **Cálculo da acurácia**:
  - Comparamos as predições com os valores verdadeiros.
- **Relatório de classificação**:
  - Usamos `classification_report` para obter métricas como precisão, recall e F1-score para cada classe.
- **Matriz de Confusão**:
  - Criamos uma matriz para visualizar o desempenho do modelo em cada classe.
  - Usamos `seaborn` para plotar a matriz de confusão.

### **Resultados Esperados**

- **Acurácia**: A proporção de predições corretas no conjunto de teste.
- **Relatório de Classificação**:
  - **Precisão (Precision)**: Proporção de predições positivas corretas.
  - **Recall**: Proporção de verdadeiros positivos identificados corretamente.
  - **F1-score**: Média harmônica entre precisão e recall.
- **Matriz de Confusão**:
  - Fornece uma visão detalhada de como o modelo está performando em cada classe.
  - Nos permite identificar onde o modelo está cometendo mais erros.

### **Interpretação dos Resultados**

- **Desempenho Geral**: Avalie se a acurácia e o F1-score são satisfatórios para o problema.
- **Classes Desbalanceadas**: Se uma classe tiver muito mais exemplos, pode afetar o desempenho. Considere técnicas de balanceamento se necessário.
- **Erros Comuns**:
  - Verifique na matriz de confusão se o modelo está confundindo sentimentos específicos.
  - Isso pode indicar a necessidade de ajustar o modelo ou melhorar o pré-processamento.

### **Possíveis Melhorias**

- **Ajuste de Hiperparâmetros**:
  - Use `GridSearchCV` ou `RandomizedSearchCV` para encontrar os melhores parâmetros para o SVM.
- **Remover Palavras Infrequentes**:
  - Ajuste os parâmetros do `CountVectorizer` para ignorar palavras muito raras ou muito comuns (`min_df`, `max_df`).
- **N-Gramas**:
  - Considere usar n-gramas (sequências de palavras) para capturar contexto adicional.
    ```python
    vectorizer = CountVectorizer(ngram_range=(1,2))
    ```
- **Normalização dos Dados**:
  - Utilize técnicas de normalização ou padronização nos dados vetorizados.
- **Feature Selection**:
  - Selecionar as features mais relevantes pode melhorar o desempenho.

### **Próximos Passos**

- **Comparar com Outros Modelos**:
  - Após treinar o SVM + BoW, treine também os outros modelos especificados (SVM + Embeddings, BERT).
  - Compare os resultados para determinar qual abordagem é mais eficaz.
- **Análise dos Erros**:
  - Examine exemplos específicos onde o modelo errou para entender possíveis causas.
- **Documentação**:
  - Registre os resultados, interpretações e insights para incluir na apresentação final.

### **Observações Finais**

- **Reprodutibilidade**:
  - Mantenha o `random_state` definido para garantir que os resultados possam ser reproduzidos.
- **Dados Fictícios**:
  - Como estamos trabalhando com dados fictícios, os resultados podem variar. Em um ambiente real, certifique-se de ter um conjunto de dados representativo.

Se tiver alguma dúvida ou precisar de assistência adicional, estou aqui para ajudar!