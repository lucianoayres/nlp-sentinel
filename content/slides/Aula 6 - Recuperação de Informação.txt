Processamento de Linguagem Natural
Recuperação de Informação

Q&A baseado em Recuperação de Informação

Aplicações

Aplicações

Aplicações

IBM Watson

Modelo de Espaço de Vetores
Documento e consulta representados por um vetor de palavras
Cada palavra é uma dimensão do vetor



Modelo de Espaço de Vetores
Espaço é do tamanho do vocabulário (alta dimensão)
Documentos são vetores esparsos
Similaridade entre os vetores da consulta e dos documentos


Similaridade de Jaccard
Tamanho da intersecção dividido pela união













Exemplo: JSim(C1,C2) = 3/8

Similaridade de Cosseno
Documentos ranqueados pela proximidade de pontos representando a consulta e os documentos


Cálculo da Similaridade
Considere dois documentos D1 e D2 e uma consulta Q 
D1 = (0.5, 0.8, 0.3), D2 = (0.9, 0.4, 0.2), Q = (1.5, 1.0, 0)

Modelo de Espaço de Vetores
Vantagens:
Eficiente
Permite casamento parcial
Fácil de implementar
Funciona bem na prática
Cons:
Assume independência dos termos
Sem informação semântica e sintática

Peso dos Termos
Termos em um documento não são igualmente úteis para descrever seu conteúdo
Ex: palavras frequentes no documento -> importantes
Ex: palavras que aparecem em todos documentos da coleção -> não importantes
Peso usado para caracterizar a importância do termo
Útil para computar ranqueamento de documentos dada uma consulta
Documentos com termos da consulta com alto peso são melhores ranqueados


Frequência do Termo no Documento - TF	
Intuição: a importância do termo em um documento é proporcional à sua frequência nele










Frequência do Termo	

Inverse Document Frequency (IDF)
Medir a especificidade de um termo
Não mede a especificidade semântica de um termo 
Depende do seu significado
Pode ser usado um thesaurus: wordnet
Ex: o termo bebida é mais genérico que café ou chá
Em RI, especificidade estatística ao invés da semântica
O inverso do número de documentos nos quais o termo ocorre



Usado amplamente em algoritmos de ranqueamento

Inverse Document Frequency (IDF): Variações

Inverse Document Frequency (IDF)

TF-IDF
Combinação do tf com o idf


Variações:



TF-IDF
TF
IDF

TF-IDF
TF
IDF

TF-IDF
TF
IDF

Exemplo: Cálculo do Cosseno usando TF-IDF
Consulta: to do

BM25
Um dos mais populares e efetivos algoritmos de ranqueamento
Baseado no BIM
3 princípios básicos: tf, idf e normalização pelo tamanho do documento
Criado como resultado de experimentos em variações de modelos probabilísticos
Usado como baseline em experimentos de RI


BM25






k1, k2 e b são parâmetros definidos empiricamente (depende da coleção)


dl: tamanho do documento

BIM
TF
Normalização
pelo tamanho
do documento 

BM25: Exemplo

BM25: Exemplo

Busca Semântica
Limitação de abordagens léxicas: 
Assume interseção entre vocabulário da pergunta e resposta
Comparação busca léxica vs semântica

Bi-encoder vs Cross Encoder
Bi-encoder
Dois encoders independentes
Eficiente: representações podem ser pré-computadas
Cross Encoder
Único encoder
Captura interações entre o par de entrada
Maior custo computacional

Retrieval Augmented Generation
Fonte: https://medium.com/enterprise-rag/an-introduction-to-rag-and-simple-complex-rag-9c3aa9bd017b

Métricas de Avaliação

Métricas
Precisão: fração de docs relevantes do total recuperados


Revocação: fração dos docs relevantes recuperados

Precisão e Revocação
Todos os docs da coleção avaliados
Em engenhos de busca: 
Docs não apresentados de uma única vez
Lista ranqueada dos docs
Varia com a posição do ranqueamento
Mais apropriado: curva de precisão e revocação

Precisão@k
Independente de recall
Número de docs relevantes no topo do ranqueamento
Precisão  em 5 (P@5): mede a precisão qdo 5 docs são apresentados

Exemplo
Resultado de consulta:






P@5= 40% e P@10= 40%

Mean Reciprocal Rank
Medir a primeira resposta correta
Q&A
Busca por sites ou URLs

MRR: Mean Reciprocal Rank
Reciprocal ranking
Ri: ranqueamento relativo à consulta qi
Scorrect(Ri): posição da primeira resposta correta em Ri
Sh: limiar para posição no ranqueamento




Para um conjunto de consultas

E-Measure
Combina precisão e revocação



b: parâmetro para dar mais peso para precisão ou revocação
(definido pelo usuário)
r(j): revocação na posição j do ranqueamento
P(j): precisão  na posição j do ranqueamento

E-Measure



b=0 
E(j) = 1 - P(j) 
E(j) se torna uma função de precisão
b -> ∞
limb -> ∞ E(j) = 1 - r(j)
E(j) se torna uma função de revocação
b=1: F-measure (média harmônica)

F-Measure
Valor único que combina precisão e revocação




Assume valores entre 0 e 1
F(j)=0: nenhum documento relevante é recuperado
F(j)=1: todos documentos relevantes são recuperados
Assume valor alto apenas quando ambos precisão e revocação são altos
Para maximizar F-measure, é preciso encontrar o melhor compromisso entre precisão e revocação

Correlação de Ranqueamento
Em alguns casos
Não conseguimos avaliar relevância diretamente
Interessados em determinar quanto um ranqueamento diferencia de outro já conhecido
Comparar ordem relativa de dois ranqueamentos
Técnicas estatísticas de correlação de ranqueamento

Correlação de Spearman
R1e R2: ranqueamentos a serem comparados
K: número de elementos no ranqueamento
sij: posição do documento no ranqueamento i na posição j 
Métricas
Correlação=1: ranqueamentos iguais
Correlação=0: completamente independentes
Correlação=-1: ranqueamento inverso


Correlação de Spearman

Correlação de Spearman

Kendal Tau
Correlação de Spearman não tem uma interpretação clara
Kendal Tau: baseado na ideia de pares de docs concordantes e discordantes em dois ranqueamentos

Kendal Tau
Considere os ranqueamentos dados por R1 e R2:





Ranqueamentos de docs por R1 e R2:

Pares de docs ordenados de R1
Pares de docs ordenados de R2

Kendal Tau
Contar or pares concordantes e descordantes
No exemplo anterior:
Para um total de 20 pares ordenados: K(K-1)
14 concordantes e 6 discordantes
Coeficiente de Kendal Tau


No exemplo:



Kendal Tau
Seja:
Número de pares discordantes:
Total de pares:  

Coeficiente kendal tau



No exemplo anterior:

Aula Prática
RAG com LlamaIndex

