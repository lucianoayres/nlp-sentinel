Processamento de Linguagem Natural
Chatbots
Prof. Luciano Barbosa

O que são
Sistemas interativos
Uso de linguagem natural
Entrada: texto ou fala
Saída: texto ou fala
IMG Source: http://ai.stanford.edu/blog/chirpy-cardinal/

Histórico
Confunde-se com a história de IA
1950-60: Turing e Weizenbaum
Computadores se comunicando como humanos
1966: Eliza (Weizenbaum)
1980-2000: projetos da DARPA
Comunicação automática com soldados
Serviço de FAQ
Teste de Turing: “se um ser humano conversa com uma máquina por cinco minutos sem perceber que ela não é humana, o computador passa no teste”

Eliza: primeiro sistema conversacional

DARPA: Defense Advanced Research Projects Agency

Exemplos
Google Assistant
Siri
Alexa
Cortana
Ex: Chatbots em sites de e-commerce ou para atendimento ao cliente

Dois tipos de Agentes Conversacionais
Agentes baseados em objetivo:
Conversas curtas
Realização de uma tarefa
Ex: reserva de hotéis ou restaurantes
Bate-papo:
Conversas mais longas
Mais próximo à interação humana (mais natural)
Ex: ELIZA
Baseados em objetivo: São agentes com função clara e específica

Bate-papo: chit·chat

Propriedades da Conversação Humana
Turns, Atos da Fala e Grounding
Turns: o agente deve identificar a vez de falar
Atos da Fala:
Grounding: Garantir que a mensagem foi recebida/entendida


Fonte: Jurafsky e Martin (2021)
Agente de viagem

C: Cliente
A: Agente

Turns
Garantia do recebimento da mensagem
Saber quando a pessoa terminou de falar
Saber quando o cliente muda de ideia no meio da conversação
Ruídos na conversação

Turns:
Cada indivíduo tem a palavra de tempos em tempos
Diálogo é uma sequência de turns
Sistema precisa saber quando falar (ex.: não esperar muito tempo depois que a pessoa terminou de falar)
Sistema precisa saber quando a pessoa terminou de falar (desafios: ruído e pausas no meio da fala)
Propriedades da Conversação Humana

Atos da Fala
Constativa: comprometer o orador com alguma condição
Responder, confirmar, negar, não concordar
Diretiva: tentativa do orador de ser atendido
Aconselhar, perguntar, pedir, convidar
Comissiva: comprometer o orador com algo futuro
Prometer, planejar, apostar, se opor
Reconhecimento: expressar reconhecimento sobre alguma atitude
Desculpar, agradecer, cumprimentar, aceitar, reconhecer
Cada sentença da conversação é algum tipo de ação executada por quem está falando (seja o usuário ou o agente)

Diretiva: 
“toque música”

S: “Que dia você quer viajar?”

Constativa:
U: “vou viajar em maio!”

É um importante componente para detectar a Intenção do usuário


Exemplo
Fonte: Jurafsky e Martin (2021)
Diretiva
Constativa
Comissiva
Reconhecimento
Diretiva: Aconselhar, perguntar, pedir, convidar

Constativa:  Responder, confirmar, negar, não concordar

Comissiva: Prometer, planejar, comprometer o orador com algo futuro

Reconhecimento: agradecer, cumprimentar, aceitar, reconhecer

Grounding
Indicar que o foi dito, foi compreendido:
A: And you said returning on May 15th?
C: Uh, yeah, at the end of the day.
A: OK

C: OK I’ll take the 5ish flight on the night before on the 11th.
A: On the 11th? OK.

C: ...I need to travel in May.
A: And, what day in May did you want to travel?
A pessoa receber alguma indicação/feedback/retorno de que a mensagem foi recebida e será respondida/resolvida de acordo

Sequências Secundárias
Sub-diálogos, Pré-sequências & Iniciativa
Um conversa tem estrutura

Perguntas geram a necessidade de uma resposta
Uma Proposta, ela gera a necessidade de uma Confirmação ou Rejeição da proposta


Sub-Diálogos: Correção
C17: #Act. . . actually#, what day of the week is the 15th?
A18: It’s a Friday.
C19: Uh hmm. I would consider staying there an extra day til Sunday.
A20: OK...OK. On Sunday I have ...
O cliente interrompe a conversa principal
O agente agora precisa responder o novo questionamento
O agente precisa detectar que o cliente agora está considerando voltar no dia 17 e não mais no dia 15.
Ainda o agente de viagem…

Um exemplo de correção

Sub-Diálogos: Clarificação
User: What do you have going to UNKNOWN_WORD on the 5th?
System: Let’s see, going where on the 5th?
User: Going to Hong Kong.
System: OK, here are some flights...
Ajuda o agente a confirmar a falta de entendimento da entrada anterior

Pré-sequências
User: Can you make train reservations?
System: Yes I can.
User: Great, I’d like to reserve a seat on the 4pm train to New York.
Identifica Intenções
Exemplos: em casos de múltiplas intenções
O usuário já iniciou a conversação perguntando se o sistema poderia fazer algo.

Reserva de trem

Intenções diferentes: reserva trem, reserva voo, reserva ônibus

Iniciativa do Diálogo
Controlada por uma pessoa
Ex: Entrevista
Mixed
Conversa natural entre pessoas
Difícil para sistemas de PLN
Iniciativa do usuário: pergunta ou fala comandos
Iniciativa do sistema: sistema faz perguntas para preencher formulário

Agentes Conversacionais
Chatbots
Para bate-papo

Chatbot: Bate-Papo
Inicialmente utilizado na área de psicologia
Baseado em regras
Eliza, Parry

Baseado em corpus (corpus de conversações)
Recuperação de Informação
Neural network encoder-decoder
Ex: BlenderBot, Xiaolce (Little Bing)
Conversa entre um psicólogo e seus pacientes

Conversa: utterance

BlenderBot

Chatbots
Baseados em Regras

Chatbots baseados em regras
Clássico:
Eliza (1966)
Parry (1968):
Usado para estudar esquizofrenia
Primeiro sistema a passar no teste de Turing
Estados de medo e raiva
Psiquiatras não conseguiram diferenciar transcripts de entrevistas reais com as produzidas por ele
Eliza: psicologia

Parry: psiquiatria

Eliza: Weizenbaum (1966)
Men are all alike.
IN WHAT WAY?
They're always bugging us about something or other.
CAN YOU THINK OF A SPECIFIC EXAMPLE?
Well, my boyfriend made me come here.
YOUR BOYFRIEND MADE YOU COME HERE?
He says I'm depressed much of the time.
I AM SORRY TO HEAR YOU ARE DEPRESSED
...
WHO ELSE IN YOUR FAMILY TAKES CARE 0F YOU?
My father
YOUR FATHER
You are like my father in some ways.
WHAT RESEMBLANCE DO YOU SEE?
You are not very aggressive but I think you don’t want me to notice that.
WHAT MAKES YOU THINK I AM NOT AGGRESSIVE?
You don’t argue with me.
WHY DO YOU THINK I DON’T ARGUE WITH YOU?
You are afraid of me.
DOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU?
My father is afraid of everybody.
WHAT ELSE COMES TO MIND WHEN YOU THINK OF YOUR FATHER?
Bullies.
DOES THAT HAVE ANYTHING TO DO WITH THE FACT THAT YOUR BOYFRIEND MADE YOU COME HERE?
Preto: paciente
Verde: o chatbot

Como funciona?
Rogerian psychologist
Estimula o paciente a falar refletindo suas frases de volta a ele
Não conhece quase nada sobre o mundo real
Objetivo é de continuar o diálogo
Patient: "I went for a long boat ride”
Psychiatrist: "Tell me about boats”
Foi projetado para simular um psicólogo rogeriano

Exemplo de Regra
(0 YOU 0 ME) →(WHAT MAKES YOU THINK I 3 YOU) 
User: You hate me
Agent: WHAT MAKES YOU THINK I HATE YOU
[padrão]
[regra]
Regra padrão-transformação: o índice na transformação indica o termo no padrão.
(0 YOU 0 ME) →(WHAT MAKES YOU THINK I 3 YOU) 

Regras
Regras ligadas a palavras que ocorrem na sentença
Palavras associadas a um ranking
Palavras mais específicas maior o ranking
Resposta com “everybody” (mais específica)
Regra para “Everybody”: (Everybody *) -> (WHO IN PARTICULAR ARE YOU THINKING OF)
“everybody” rank 5 / “I” rank 0 → “everybody” > “I” → escolher padrão para “everybody”
Agent: WHO IN PARTICULAR ARE YOU THINKING OF?
User: I know everybody laughed at me
Regra para sentenças com a palavra “I”: (I *) → (You say you 2)
Agent: YOU SAY YOU KNOW EVERYBODY LAUGHED AT YOU

Sem Casamento de Keyword
Não foi detectado padrão
Resposta que não comprometa

PLEASE GO ON
THAT’S VERY INTERESTING
I SEE
…
Uma forma de resolver quando o chatbot não entende algo que o usuário falou

Memória
Armazena conversas passadas e as usa quando nenhuma keyword dá match
Frases com “my”
Quando não entende alguma coisa dita
O sistema armazena conversas para serem respondidas depois
(Atualizar as regras do chatbot)


Implicações Éticas
O risco de as pessoas se envolverem emocionalmente com o programa
Alguns pediram pra ficar a sós com o bot
Usuários não queriam que os diálogos fossem logados -> diálogos bem pessoais

Chatbots
Baseados em Corpus

Chatbots Baseado em Corpus
Usa corpus com conversações ao invés de regras
Corpus: conversas naturais
Ex: ligações telefônicas, diálogo de filmes, tweets, reddit
Criadas usando crowdsourcing
Topical-Chat dataset (11k conversas em 8 tópicos)
EMPATHETICDIALOGUES: 25k conversas focado em emoções
Extrair fatos do Wikipedia ou notícias

Duas Estratégias
By retrieval
Usa recuperação de informação para obter no corpus
By generation
Usa modelo de linguagem ou encoder-decoder para construir a resposta
GPT3 Demo: https://www.youtube.com/watch?v=V-M5SVta2uw 

Limitação
Podem ser repetitivos e monótonos
A: Where are you
going?
B: I’m going to the
restroom.
A: See you later.
B: See you later.
A: See you later.
B: See you later.
A: How old are you?
B: I’m 16.
A: 16?
B: I don’t know what you are
talking about.
A: You don’t know what you
are saying.
B: I don’t know what you are
talking about.
A: You don’t know what you
are saying.

Arquiteturas Híbridas
Baseado em regras, corpus e baseado em frames
http://ai.stanford.edu/blog/chirpy-cardinal/
https://par.nsf.gov/servlets/purl/10318326
Chirpy: construído utilizando as 3 abordagens (regras, corpus, frames)

FORCE_START: regra para iniciar a conversação
STRONG_CONTINUE: requisita um prompt (resposta) que é coletado pelo “Neural Chat”
Movie: identifica a intenção da sentença (falando sobre filmes)
Entidade: detecta a entidade mentionada “The Matrix” “keany Reeves”

Ainda podem ser construídos utilizando:
Wikipedia entity linking (desambiguar entidades) podem ter o mesmo nome e ser coisas diferentes
Classificação de entidade
Classificação de atos do diálogo
Modelos de linguagem para gerar a resposta

Em Resumo
Pros:
Divertido
Bom para aplicações específicas e bem estruturadas (regras)
Limitações:
Não compreendem
Chatbots baseados em regras são custosos pra construir
Basedo em RI: depende muito da qualidade do corpus
Ideal: combinar chatbots com agentes baseados em objetivo
Chatbot para banco: Quais as tarefas o bot vai desempenhar? As mesmas tarefas que no banco físico?

Ideal: objetivo claro e fazer muito bem


Agentes Conversacionais Baseados em Objetivo 

Baseados em Tarefa
Objetivo de resolver uma tarefa para um usuário: reservar um voo ou comprar um produto
Arquitetura GUS
Criada em 1977
Usada pelos assistentes virtuais atuais
Baseada em frames
Frames = formulário

Cada slot é relacionado a uma intenção do usuário


Frame/Template
Conjunto de slots a serem preenchidos na conversação
Cada frame associado a uma pergunta

Modos de Funcionamento
Sistema faz perguntas ao usuário?
Usuário pode preencher vários slots de uma vez?
I want a flight from San Francisco to Denver one way leaving after five p.m. on Tuesday.
Busca na base após preenchimento do frame

Múltiplos Frames
Fonte: https://freshdesk.com/self-service-portal/improve-chatbot-conversation-blog/
Fluxo múltiplos frames para resolução de vários objetivos, fluxo de perguntas, ações a serem executadas de cada vez

Natural Language Understanding
Domain, Intent & Slot Fillers

Arquitetura
Natural Language Understanding
Dialog Manager
Natural Language Generation
Chatbot
Ainda não recebi o meu Xiaomi 12. Quando ele será entregue?
Por favor, digite o número do seu pedido
Natural Language Understanding: identifica intenção, domínio e identifica as entidades/informações recebidas utilizando Modelos de Machine e até Deep Learning

Natural Language Generation: Modelos de Machine e Deep Learning (Modelos de linguagem)

Dialog Manager: é o “cérebro” do bot que contém as regras, gerencia o domínio, a intenção do usuário, e as informações que foram recebidas.. Decide a ação

O Dialog Manager é um elemento mais sofisticado (do que frames) para os sistemas conversacionais baseados em tarefa

É mais complexo que o GUS

Natural Language Understanding
Classificação do domínio
É preciso identificar qual o contexto da conversação do usuário
Trivial para tarefas simples: Alarme, transação sobre um produto, uso de calendário
Necessário em sistemas de diálogo de múltiplos domínios (comuns atualmente)
Determinar intenção: qual a tarefa?
Encontrar um filme, remover um alarme, comprar uma passagem aérea
Slot Fillers: 
Preenchimento dos campos a partir da entrada do usuário
DOMAIN: 	PRODUTO
INTENT:	INFO-ENTREGA
PRODUTO:	XIAOMI 12
Natural Language Understanding
Ainda não recebi o meu Xiaomi 12. Quando ele será entregue?
Essa arquitetura possui componentes para extração de informação lá do texto entregue pelo usuário para completar os formulários
Só que são utilizados modelos de Machine Learning ao invés de regras.

Exemplo
Resolução de entidade: texto “six” -> datetime

Exemplo
Resolução de Entidade: SF -> San Francisco

Preenchimento de Campos
Baseado em regras
Intenção -> Palavras ativadoras

Machine Learning
Classificador para classificação de domínio, intenção e extração dos campos
Necessita de dados rotulados

Dialog Manager
“Cérebro” do sistema
Identificar o estado atual
Salva o contexto
Decide a próxima ação
DOMAIN: 	PRODUTO
INTENT:	INFO-ENTREGA
PRODUTO:	XIAOMI 12
Natural Language Understanding
Dialog Manager
Ação: solicitar número do pedido
Ainda não recebi o meu Xiaomi 12. Quando ele será entregue?
O Dialog Manager vai possuir um rastreador de estados da conversação e uma política de diálogo.

Então ele armazena as últimas coisas que o usuário está solicitando ou conversando com o sistema (contexto)

A política de diálogo decide o que o sistema deve fazer ou dizer

Atos do Diálogo
Descrevem os possíveis estados do diálogo
Os atos do diálogo são utilizados pelo rastreador do diálogo

Cada sistema deve ter rótulos sobre os atos de diálogo para sua finalidade

Os rótulos HELLO(a, b,... ) podem ser vistos como funções

Parâmetros são informações detectadas na conversação para preenchimento de slots

Atos do diálogo
Classificador multiclasse para identificar a tag baseado no contexto
Extrator para identificar os slots
U: Usuário
S: Sistema

Dialogue Policy
Predizer a próxima ação dada toda a conversa

Ou dados campos preenchidos, últimas “rodadas” do usuário e sistema

Baseado em um classificador/busca ou fluxo de conversação
Decide qual ação tomar ou o que responder ao usuário

Confirmação e Rejeição
Lidar com erros do sistema
Ter certeza que o usuário foi compreendido
Dois mecanismos
Confirmação
Rejeição

Confirmação Explícita
O sistema utiliza perguntas diretas para confirmar o entendimento. (Yes/No questions)
É mais fácil para que o usuário corrija o entendimento errado do sistema
É estranho, apresenta um aspecto não natural e não humano na conversação
Prolonga a conversação

Confirmação Implícita
O sistema utiliza a estratégia de grounding: repete o entendimento como parte de uma nova questão
Apresenta um aspecto mais natural à conversação

Rejeição
Uma forma de o sistema mostrar que não entende a entrada do usuário
Ao invés de simplesmente repetir que não entendeu a entrada (Ex: “I’m sorry, I didn’t understand that”)
Prompting progressivo

Natural Language Generation
Gera o texto para o ato do diálogo
Escolhe alguns atributos para colocar no texto
Mostrar ao usuário uma resposta ou pedir confirmação
Preenchimento de template
Em tempo de geração de respostas para o usuário podem ser utilizados templates de sentenças diferentes, com slots que podem ser preenchidos com a informação necessária

A preocupação deve ser em “o que responder” e “como responder”

Encoder-Decoder

NLG usando Classificador
Usa conversações
“Deslexização” de palavras que representam slots
Delexicalizar = mudar a estrutura da sentença

Avaliação
São avaliados por humanos
Avaliação participativa (conversa com o chat)
Avaliação observadora (transcrição da conversação)
Dimensões de qualidade:
Engajamento: o quanto foi satisfatória a interação
Evitar repetições
Fluência
Fazer sentido
Interesse
Curiosidade
Humanidade
Ação de escuta

Avaliação
Pesquisas recentes em avaliação adversarial baseada no teste de turing
Agentes baseados em tarefas não ambíguas:
Slot error rate por sentença
“Make an appointment with Chris at 10:30 in Gates 104”
SLOT
PREENCHIMENTO
pessoa
Chris
horário
11:30
local
Gates 104
Slot Error Rate: 1/3
Adversarial
Gerador: gera o texto
Objetivo: enganar o avaliador

Avaliador: classificador
Objetivo:  avaliar se o texto é parecido com o que um humano escreveria

O sistema de geração deverá enganar o avaliador de forma a melhorar a resposta gerada
Sempre que o avaliador distinguir que o texto foi gerado por máquina, o gerador vai atualizar seu modelo de forma a gerar um texto melhor

Bases de Dados para treino de chatbots
http://yanran.li/dailydialog 
https://github.com/google-research-datasets/ccpe 
https://github.com/google-research-datasets/dstc8-schema-guided-dialogue 
https://github.com/howl-anderson/ATIS_dataset 
https://github.com/amazon-research/nlu-slot-constraints 
https://github.com/MiuLab/SlotGated-SLU/tree/master/data/snips 
https://github.com/MiuLab/SlotGated-SLU/tree/master/data/atis
https://towardsdatascience.com/complete-guide-to-building-a-chatbot-with-spacy-and-deep-learning-d18811465876 

Referências
Dan Jurafsky, James H. Martin. Speech and Language Processing. (3rd ed. Draft). 2021. Disponível em: <https://web.stanford.edu/~jurafsky/slp3/15.pdf>. Capítulo 15 Acesso em: 03 de Março de 2023.
