# -*- coding: utf-8 -*-
"""Pos-Deep-Learning-Projeto-NPL-Sentinel-22-Dez-2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WwAcQrNEa5Md1hhqvQt9R4uDtFJ57JS8

# ðŸ›¡ï¸ NPL-Sentinel

![NPL Sentinel Banner](https://github.com/lucianoayres/npl-sentinel/raw/main/images/sentinel_banner.png)

## AnÃ¡lise de Sentimento em AvaliaÃ§Ãµes de Produtos

- #### Curso: PÃ³s-GraduaÃ§Ã£o em Deep Learning (CIn - UFPE)
- ##### Disciplina: Processamento de Linguagem Natural  
  - ##### Professor: Luciano Barbosa

- ##### ðŸ‘¥ Grupo:
  - Paloma CorrÃªa Alves (pca2@cin.ufpe.br)
  - Luciano Ayres Farias de Carvalho (lafc@cin.ufpe.br)

## ðŸ“– Sobre o Projeto

### ðŸ” VisÃ£o Geral  
O **NPL-Sentinel** Ã© um projeto que explora **Processamento de Linguagem Natural (PLN)** para analisar sentimentos expressos em avaliaÃ§Ãµes de consumidores sobre um produto: um **smartphone**. ðŸ“±âœ¨

### ðŸŽ¯ Objetivo  
Este projeto tem como **meta principal** identificar a polaridade dos sentimentos (ðŸ˜Š Positivo, ðŸ˜ Neutro, ðŸ˜ž Negativo) contidos nas avaliaÃ§Ãµes dos consumidores. AlÃ©m disso:  
- **ðŸ“ˆ Correlacionar** a polaridade dos sentimentos com as notas atribuÃ­das pelos consumidores, validando a precisÃ£o do modelo.  
- **ðŸ” Realizar anÃ¡lises exploratÃ³rias** para identificar padrÃµes nas avaliaÃ§Ãµes, destacando os aspectos mais comentados em avaliaÃ§Ãµes positivas e negativas.  

### ðŸ¤– Modelos Utilizados  
ðŸ”¹ **SVM + Bag of Words (BoW)**  
ðŸ”¹ **SVM + Embeddings**  
ðŸ”¹ **BERT**  
ðŸ”¹ **In-Context Learning**: OpenAI  
ðŸ”¹ **In-Context Learning**: Google Gemini  

### ðŸ“‘ Sobre os Dados  
Os dados utilizados consistem em:  
- **ðŸ’¬ review:** ComentÃ¡rio livre do consumidor sobre o produto (smartphone).  
- **â­ rating:** Nota (1 a 5) atribuÃ­da pelo consumidor, indicando sua satisfaÃ§Ã£o com o smartphone.  

### ðŸ’¡ Por que NPL-Sentinel?  
Porque a ideia Ã© ir alÃ©m da anÃ¡lise bÃ¡sica, atuando como um "sentinela" que monitora tendÃªncias, sentimentos e insights valiosos diretamente das opiniÃµes dos consumidores. ðŸš€

# 1. Carregamento dos Dados
"""

import pandas as pd

# URL do arquivo CSV remoto
url = "https://raw.githubusercontent.com/lucianoayres/npl-sentinel/refs/heads/main/data/reviews.csv"

# Carrega o arquivo CSV em um DataFrame do pandas
df = pd.read_csv(url)

# Salva o DataFrame localmente no Google Colab
df.to_csv("reviews.csv", index=False)

# Exibe as primeiras linhas do DataFrame (opcional)
print(df.head())

# Exibe tipos de dados de cada coluna
print("\nTipos de dados de cada coluna:")
df.info()

# Imprime um describe detalhado, incluindo todas as colunas
print("\nDescriÃ§Ã£o detalhada dos dados:")
print(df.describe(include='all'))

# EstatÃ­sticas descritivas para variÃ¡veis categÃ³ricas
print("\nEstatÃ­sticas descritivas para variÃ¡veis categÃ³ricas:")
print(df.describe(include=['object']))

"""# 2. PrÃ©-processamento dos Dados

Uso do `nltk` para tokenizaÃ§Ã£o, remoÃ§Ã£o de stopwords e outras tÃ©cnicas de limpeza.
"""

import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from nltk.corpus import stopwords
import string
import pandas as pd  # Ensure pandas is imported

# Faz o download das stopwords
nltk.download("stopwords")
stop_words = stopwords.words("portuguese")

# FunÃ§Ã£o para prÃ©-processar o texto
def preprocess_text(text):
    if not isinstance(text, str):
        return ""  # Retorna string vazia se o texto nÃ£o for string
    text = text.lower()  # Converte para minÃºsculas
    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove pontuaÃ§Ã£o
    text = "".join([char for char in text if char.isalnum() or char.isspace()])  # Remove caracteres nÃ£o alfanumÃ©ricos
    tokens = [word for word in text.split() if word not in stop_words]  # Remove stopwords
    return " ".join(tokens)  # Junta os tokens de volta em uma string

# Verifica e remove linhas com review ou rating vazio antes de qualquer processamento
empty_reviews = df["review"].isnull() | (df["review"].astype(str).str.strip() == "")
empty_ratings = df["rating"].isnull() | (df["rating"].astype(str).str.strip() == "")
initial_count = df.shape[0]
df = df[~(empty_reviews | empty_ratings)].copy()
removed_reviews = initial_count - df.shape[0]

# Exibe a quantidade de reviews e ratings vazios removidos
print("\nItens Removidos:")
print("Reviews ou Ratings vazios:", removed_reviews)

# Converte a coluna 'rating' para inteiro, tratando possÃ­veis erros
df["rating"] = pd.to_numeric(df["rating"], errors='coerce')

# Remove quaisquer linhas onde a conversÃ£o falhou (resultado em NaN)
invalid_ratings = df["rating"].isnull()
if invalid_ratings.any():
    print(f"Removendo {invalid_ratings.sum()} linhas com ratings invÃ¡lidos apÃ³s conversÃ£o.")
    df = df[~invalid_ratings]

# Aplica a funÃ§Ã£o de prÃ©-processamento Ã  coluna 'review'
df["clean_review"] = df["review"].apply(preprocess_text)

# FunÃ§Ã£o para converter notas em rÃ³tulos de sentimento
def convert_to_sentiment(rating):
    if rating >= 4:
        return "positivo"
    elif rating <= 2:
        return "negativo"
    else:
        return "neutro"

# Aplica a funÃ§Ã£o de conversÃ£o Ã  coluna 'rating'
df["sentiment"] = df["rating"].apply(convert_to_sentiment)

# Opcional: Exibe um resumo das conversÃµes
print("\nDistribuiÃ§Ã£o de Sentimentos:")
print(df["sentiment"].value_counts())

# Exemplo de visualizaÃ§Ã£o do DataFrame resultante
print("\nExemplo de dados processados:")
print(df.head())

"""# 3. AnÃ¡lise Descritiva

## 3.1. DistribuiÃ§Ã£o das Notas (rating)
"""

import pandas as pd
import nltk
import matplotlib.pyplot as plt
import seaborn as sns

# AnÃ¡lise da DistribuiÃ§Ã£o das Notas
plt.figure(figsize=(8, 6))
ax = sns.countplot(x='rating', data=df, hue='rating', palette='pastel', legend=False)  # Changes here

# Adiciona os totais em cima das barras
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 5), textcoords='offset points')

plt.title('DistribuiÃ§Ã£o das Notas')
plt.xlabel('Nota')
plt.ylabel('FrequÃªncia')
plt.show()

"""### Resultados Totais da DistribuiÃ§Ã£o das Notas"""

# Imprime os totais para cada nota
print("\nResultados Totais da DistribuiÃ§Ã£o das Notas:")
rating_counts = df['rating'].value_counts().sort_index()
for rating, count in rating_counts.items():
    print(f"Nota {rating}: {count} avaliaÃ§Ãµes")

"""## 3.2. Histograma do Comprimento das AvaliaÃ§Ãµes (review)

"""

import pandas as pd
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

plt.figure(figsize=(8, 6))
plt.hist(df['review'].str.len(), bins=50)
plt.title('Histograma do Comprimento das AvaliaÃ§Ãµes')
plt.xlabel('Comprimento da AvaliaÃ§Ã£o (caracteres)')
plt.ylabel('FrequÃªncia')
plt.show()

"""### EstatÃ­sticas do Comprimento das AvaliaÃ§Ãµes"""

import pandas as pd
import numpy as np

review_lengths = df['review'].str.len()
hist, bin_edges = np.histogram(review_lengths, bins=50) # Calculate hist and bin_edges

# Cria um DataFrame para estatÃ­sticas resumidas
summary_data = {
    "MÃ©trica": ["Total de AvaliaÃ§Ãµes", "Comprimento MÃ©dio", "Comprimento MÃ­nimo", "Comprimento MÃ¡ximo", "Desvio PadrÃ£o"],
    "Valor": [
        len(review_lengths),
        f"{review_lengths.mean():.2f} caracteres",
        f"{review_lengths.min()} caracteres",
        f"{review_lengths.max()} caracteres",
        f"{review_lengths.std():.2f} caracteres",
    ],
}
summary_df = pd.DataFrame(summary_data)

# Cria um DataFrame para a distribuiÃ§Ã£o de comprimentos
distribution_data = {
    "Intervalo de Comprimento": [f"{bin_edges[i]:.0f}-{bin_edges[i+1]:.0f}" for i in range(len(hist))],
    "FrequÃªncia (AvaliaÃ§Ãµes)": hist,
}
distribution_df = pd.DataFrame(distribution_data)

# Exibe as tabelas
print("EstatÃ­sticas Resumidas:")
print(summary_df.to_string(index=False))  # index=False para ocultar os nÃºmeros das linhas

print("\nDistribuiÃ§Ã£o de Comprimentos:")
print(distribution_df.to_string(index=False))

"""## 3.3. Nuvem de Palavras

"""

!pip install wordcloud
from wordcloud import WordCloud
text = ' '.join(df['clean_review'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Nuvem de Palavras')
plt.show()

"""### Resultados para a Nuvem de Palavras"""

import pandas as pd

# Obter as palavras mais frequentes e suas frequÃªncias
word_freq = wordcloud.words_

# Criar um DataFrame para armazenar as palavras e frequÃªncias
top_words_df = pd.DataFrame(list(word_freq.items())[:10], columns=['Palavra', 'FrequÃªncia'])

# Exibir o DataFrame como uma tabela
print("Top 10 palavras mais frequentes:")
print(top_words_df.to_string(index=False))

"""## 3.4 FrequÃªncia das Entidades (review)

"""

# Faz o Download do Modelo de Linguagem PT-BR
!python -m spacy download pt_core_news_md

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from collections import Counter
import spacy

import plotly.express as px

# Carregamento do modelo de linguagem do spaCy
nlp = spacy.load('pt_core_news_md')

# PrÃ©-processamento com spaCy
def preprocess(text):
    doc = nlp(text)
    tokens = [
        token.lemma_.lower() for token in doc
        if not token.is_stop and not token.is_punct and not token.like_num
    ]
    return ' '.join(tokens)

df['clean_review'] = df['review'].astype(str).apply(preprocess)

# AnÃ¡lise de Entidades Nomeadas com spaCy
def extract_entities(text):
    doc = nlp(text)
    return [ent.text for ent in doc.ents if ent.label_ in ['ORG', 'PERSON', 'LOC', 'PRODUCT']]

df['entities'] = df['review'].astype(str).apply(extract_entities)

# Contagem das entidades mais frequentes
all_entities = [entity for sublist in df['entities'] for entity in sublist]
entity_freq = Counter(all_entities).most_common(20)

# VisualizaÃ§Ã£o: FrequÃªncia das Entidades
entities_df = pd.DataFrame(entity_freq, columns=['Entidade', 'FrequÃªncia'])
plt.figure(figsize=(12, 8))
sns.barplot(x='FrequÃªncia', y='Entidade', data=entities_df, palette='magma', hue='Entidade', dodge=False)  # Modified line
plt.title('Top 20 Entidades Nomeadas Mais Frequentes')
plt.xlabel('FrequÃªncia')
plt.ylabel('Entidade')
plt.tight_layout()
plt.show()

"""## 3.5 AnÃ¡lise de N-grams (Bigrams e Trigrams com TF-IDF)"""

# AnÃ¡lise de N-grams AvanÃ§ada (Bigrams e Trigrams com TF-IDF)
def get_top_ngrams(corpus, n=None, top=None):
    vec = TfidfVectorizer(ngram_range=(n, n)).fit(corpus)
    bag_of_words = vec.transform(corpus)
    sum_words = bag_of_words.sum(axis=0)
    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)
    return words_freq[:top]

top_bigrams = get_top_ngrams(df['clean_review'], n=2, top=10)
top_trigrams = get_top_ngrams(df['clean_review'], n=3, top=10)

# VisualizaÃ§Ã£o de Bigrams
bigrams_df = pd.DataFrame(top_bigrams, columns=['Bigram', 'TF-IDF'])
plt.figure(figsize=(10, 6))
sns.barplot(x='TF-IDF', y='Bigram', data=bigrams_df, hue='Bigram', palette='coolwarm', dodge=False, legend=False) # Modified line
plt.title('Top 10 Bigrams com Maior TF-IDF')
plt.xlabel('TF-IDF')
plt.ylabel('Bigram')
plt.tight_layout()
plt.show()

# VisualizaÃ§Ã£o de Trigrams
trigrams_df = pd.DataFrame(top_trigrams, columns=['Trigram', 'TF-IDF'])
plt.figure(figsize=(10, 6))
sns.barplot(x='TF-IDF', y='Trigram', data=trigrams_df, hue='Trigram', palette='coolwarm', dodge=False, legend=False)
plt.title('Top 10 Trigrams com Maior TF-IDF')
plt.xlabel('TF-IDF')
plt.ylabel('Trigram')
plt.tight_layout()
plt.show()

"""## 3.6 AnÃ¡lise do Comprimento da AvaliaÃ§Ã£o vs. Nota com RegressÃ£o"""

# AnÃ¡lise do Comprimento da AvaliaÃ§Ã£o vs. Nota com RegressÃ£o
df['review_length'] = df['review'].astype(str).apply(len)

plt.figure(figsize=(10, 6))
sns.regplot(x='review_length', y='rating', data=df, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})
plt.title('RelaÃ§Ã£o entre Comprimento da AvaliaÃ§Ã£o e Nota')
plt.xlabel('Comprimento da AvaliaÃ§Ã£o (caracteres)')
plt.ylabel('Nota')
plt.show()

"""### CorrelaÃ§Ã£o entre Comprimento da AvaliaÃ§Ã£o e Nota"""

# Calcular e imprimir a correlaÃ§Ã£o
correlation = df['review_length'].corr(df['rating'])
print("-" * 50)
print(f"Coeficiente de correlaÃ§Ã£o de Pearson: {correlation:.2f}")
print("-" * 50)

"""# 4. Treinamento de Classificadores

## 4.1 SVM + Bag of Words (BoW)
"""

from sklearn.model_selection import GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, f1_score

# Divide o dataset
X_train, X_test, y_train, y_test = train_test_split(df["clean_review"], df["rating"], test_size=0.2, random_state=42)

# Atualiza a pipeline usando TF-IDF no lugar de CountVectorizer
pipeline_tfidf = Pipeline([
    ("tfidf", TfidfVectorizer()),
    ("classifier", SVC())
])

# Grade de parÃ¢metros para o GridSearch
param_grid = {
    "tfidf__ngram_range": [(1,1), (1,2)],
    "tfidf__max_features": [1000, 3000, 5000],
    "classifier__C": [0.1, 1, 10],
    "classifier__kernel": ["linear", "rbf"]
}

# Aplica o GridSearch para encontrar a melhor combinaÃ§Ã£o de hiperparÃ¢metros
grid_search = GridSearchCV(pipeline_tfidf, param_grid, cv=3, scoring='f1_weighted', n_jobs=-1)
grid_search.fit(X_train, y_train)

# ObtÃ©m o melhor modelo
best_svm_model = grid_search.best_estimator_

# Faz a prediÃ§Ã£o no conjunto de teste
y_pred_bow = best_svm_model.predict(X_test)

"""### AvaliaÃ§Ã£o dos Resultados para o SVM + Bag of Words (BoW)"""

# AvaliaÃ§Ã£o
print("SVM + Bag of Words")
print(classification_report(y_test, y_pred_bow))

# Calcula a acurÃ¡cia e F1 score
accuracy_bow = accuracy_score(y_test, y_pred_bow)
f1_bow = f1_score(y_test, y_pred_bow, average='weighted')

print(f"Accuracy: {accuracy_bow}")
print(f"F1-score: {f1_bow}")

"""### Matriz de ConfusÃ£o para o SVM + Bag of Words (BoW)"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Function to create a confusion matrix heatmap
def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))
    plt.title(title)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

# Plot the confusion matrix for the BoW model
plot_confusion_matrix(y_test, y_pred_bow, title="Confusion Matrix - SVM + Bag of Words")

"""## 4.2 SVM + Embeddings

Uso de `spacy` para converter as avaliaÃ§Ãµes em embeddings e treinar o SVM com esses vetores.
"""

# Faz o Download do Modelo de Linguagem PT-BR
!python -m spacy download pt_core_news_md

import spacy
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# Usa embeddings do spaCy
nlp = spacy.load("pt_core_news_md")
X_train_embedded = [nlp(text).vector for text in X_train]
X_test_embedded = [nlp(text).vector for text in X_test]

# Normaliza os embeddings
scaler = StandardScaler()
X_train_embedded = scaler.fit_transform(X_train_embedded)
X_test_embedded = scaler.transform(X_test_embedded)

# Treina o SVM com embeddings
svm_embedding = SVC()
svm_embedding.fit(X_train_embedded, y_train)
y_pred_embed = svm_embedding.predict(X_test_embedded)

"""### AvaliaÃ§Ã£o dos Resultados para o SVM + Embeddings"""

# AvaliaÃ§Ã£o
print("SVM + Embeddings")
print(classification_report(y_test, y_pred_embed))

# Calcula a acurÃ¡cia e F1 score
accuracy_embed = accuracy_score(y_test, y_pred_embed)
f1_embed = f1_score(y_test, y_pred_embed, average='weighted')

print(f"Accuracy: {accuracy_embed}")
print(f"F1-score: {f1_embed}")

"""### Matriz de ConfusÃ£o para o SVM + Embedding"""

plot_confusion_matrix(y_test, y_pred_embed, title="Confusion Matrix - SVM + Embeddings")

"""## 4.3 BERT para ClassificaÃ§Ã£o

Usando `transformers` para fine-tuning de um modelo BERT para classificaÃ§Ã£o de sentimentos.
"""

from transformers import BertTokenizer, TFBertForSequenceClassification, AdamWeightDecay

import tensorflow as tf

# Restringe o TensorFlow para usar apenas a CPU
# tf.config.set_visible_devices([], 'GPU')

# Prepara o modelo BERT
tokenizer = BertTokenizer.from_pretrained("neuralmind/bert-base-portuguese-cased")
model = TFBertForSequenceClassification.from_pretrained("neuralmind/bert-base-portuguese-cased", num_labels=5)

# Tokeniza os dados
X_train_tokens = tokenizer(list(X_train), padding=True, truncation=True, return_tensors="tf")
X_test_tokens = tokenizer(list(X_test), padding=True, truncation=True, return_tensors="tf")

# Define o otimizador e a funÃ§Ã£o de perda
optimizer = AdamWeightDecay(learning_rate=3e-5)
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metrics = tf.keras.metrics.SparseCategoricalAccuracy()

# Loop de treinamento personalizado
def train_step(inputs, targets):
    # Subtrai 1 dos targets para ajustar o intervalo para 0-4
    targets = targets - 1
    with tf.GradientTape() as tape:
        predictions = model(inputs)
        loss = loss_fn(targets, predictions.logits)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    metrics.update_state(targets, predictions.logits)
    return loss, metrics.result()

# Loop de Treinamento
epochs = 4
batch_size =8
for epoch in range(epochs):
    print(f"Epoch {epoch + 1}/{epochs}")
    for i in range(0, len(X_train), batch_size):
        batch_inputs = {k: v[i:i + batch_size] for k, v in X_train_tokens.data.items()}
        batch_targets = y_train[i:i + batch_size]
        # Subtraindo 1 dos targets para ajustar o intervalo para 0-4
        loss, accuracy = train_step(batch_inputs, batch_targets)
        print(f"Batch {i // batch_size + 1}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}")

"""### AvaliaÃ§Ã£o dos Resultados para o BERT"""

import numpy as np
from sklearn.metrics import accuracy_score, f1_score

# AvaliaÃ§Ã£o
predictions = model(X_test_tokens.data).logits

# ObtÃ©m os rÃ³tulos previstos a partir dos logits
predicted_labels = np.argmax(predictions, axis=1)

# Ajusta y_test para o intervalo 0-4 para avaliaÃ§Ã£o (se necessÃ¡rio)
y_test_adjusted = y_test - 1

# Calcula as mÃ©tricas
accuracy_bert = accuracy_score(y_test_adjusted, predicted_labels)
f1_bert = f1_score(y_test_adjusted, predicted_labels, average='weighted')
loss = loss_fn(y_test_adjusted, predictions) # Calcula a perda apÃ³s o ajuste do y_test

print("\nBERT:")
print(f"Test Loss: {loss:.4f}") # Imprime a perda
print(f"AcurÃ¡cia: {accuracy_bert:.4f}")
print(f"F1 Score: {f1_bert:.4f}")

"""### Matriz de ConfusÃ£o para o Resultado do BERT"""

# ### Matriz de ConfusÃ£o para o Resultado do BERT
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Plot the confusion matrix for the BERT model
def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))
    plt.title(title)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

plot_confusion_matrix(y_test_adjusted, predicted_labels, title="Confusion Matrix - BERT")

"""# 5. Comparativo de MÃ©tricas e Resultados

Resultado comparativo entre os trÃªs modelos (SVM + BoW, SVM + Embebddings e BERT).
"""

# Cria um dicionÃ¡rio com os resultados
resultados = {
    "Modelo": ["SVM + Bag of Words", "SVM + Embeddings", "BERT"],
    "AcurÃ¡cia": [accuracy_bow, accuracy_embed, accuracy_bert],
    "F1-Score": [f1_bow, f1_embed, f1_bert]
}

# Cria um DataFrame pandas com os resultados
df_resultados = pd.DataFrame(resultados)

# Exibe o DataFrame
print(df_resultados)

"""### GrÃ¡fico com ComparaÃ§Ã£o de Desempenho dos Modelos"""

import matplotlib.pyplot as plt
import pandas as pd

plt.figure(figsize=(10, 6))
df_resultados.plot(x="Modelo", y=["AcurÃ¡cia", "F1-Score"], kind="bar", width=0.6, color=['skyblue', 'lightcoral'])
plt.title("ComparaÃ§Ã£o de Desempenho dos Modelos")
plt.ylabel("PontuaÃ§Ã£o")
plt.xticks(rotation=0)
plt.legend(title="MÃ©trica")
plt.tight_layout()
plt.show()

"""# 6. ClassificaÃ§Ã£o com In-Context Learning (BÃ´nus)

Utilizando LLM para realizar a classificaÃ§Ã£o de sentimentos diretamente com poucas instruÃ§Ãµes, sem a necessidade de treinamento explÃ­cito.
"""

# Define o temeplate do prompt
prompt_template = """
VocÃª Ã© um assistente de anÃ¡lise de sentimentos. Sua tarefa Ã© classificar avaliaÃ§Ãµes de produtos como "positivo", "negativo" ou "neutro".

Aqui estÃ¡ uma avaliaÃ§Ã£o de um produto:
{review_text}

Classifique a avaliaÃ§Ã£o acima como "Positivo", "Neutro" ou "Negativo". Responda apenas com a classificaÃ§Ã£o, sem adicionar comentÃ¡rios ou explicaÃ§Ãµes adicionais.
"""

# Define funÃ§Ã£o para exibiÃ§Ã£o da classificaÃ§Ã£o
def add_emoji_to_classification(classification):
  if classification == "Positivo":
    return "ðŸ˜Š " + classification
  elif classification == "Neutro":
    return "ðŸ˜ " + classification
  elif classification == "Negativo":
    return "ðŸ˜ž " + classification
  else:
    return classification

# Define funÃ§Ã£o para comparaÃ§Ã£o com resultado da coluna "sentiment"
def compare_classification_with_actual(classification, actual_sentiment):
  is_correct = classification.lower() == actual_sentiment.lower()
  result = "âœ… Correto" if is_correct else "âŒ Incorreto"
  return result, is_correct

"""## 6.1 Using OpenAI (GPT-4o)"""

!pip install -qU langchain-openai

import os
from google.colab import userdata

from google.colab import userdata
from langchain_openai import ChatOpenAI

os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY')

llm = ChatOpenAI(
    model_name="gpt-4o",
    temperature=0
)

def classify_with_openai(review_text):
    prompt = prompt_template.format(review_text=review_text)

    response = llm.predict(prompt)
    return response.strip()

random_reviews = df.sample(n=10)

print("ClassificaÃ§Ã£o da OpenAI GPT-4")
print("=" * 90)

for index, row in random_reviews.iterrows():
    review_text = row['review']
    classification = classify_with_openai(review_text)
    display_classification = add_emoji_to_classification(classification)
    result, is_correct = compare_classification_with_actual(classification, row['sentiment'])

    print(f"\nAvaliaÃ§Ã£o: {review_text}")
    print(f"ClassificaÃ§Ã£o da OpenAI: {display_classification}")
    print("-" * 90)
    print(f"Sentimento Real: {row['sentiment'].capitalize()}")
    print(f"Resultado: {result}")

"""## 6.2 Using Google Gemini 1.5"""

from google.colab import userdata
import google.generativeai as genai

# Retorna a chave de API do Google Gemini do userdata
myKey = userdata.get('GOOGLE_API_KEY')
genai.configure(api_key=myKey)

# Espcifica o modelo do Gemini
model = genai.GenerativeModel("gemini-1.5-flash-latest")

def classify_with_gemini(review_text):
    response = model.generate_content(prompt_template.format(review_text=review_text))
    classification = response.text.strip()
    return classification

# Classifica 10 reviews aleatÃ³rias
random_reviews = df.sample(n=10)

print("ClassificaÃ§Ã£o do Google Gemini 1.5")
print("=" * 90)

for index, row in random_reviews.iterrows():
    review_text = row['review']
    classification = classify_with_gemini(review_text)

    # Adiciona o emoji
    display_classification = add_emoji_to_classification(classification)

    # Compara o resultado com o sentimento correto
    result, is_correct = compare_classification_with_actual(classification, row['sentiment'])

    print(f"\nAvaliaÃ§Ã£o: {review_text}")
    print(f"ClassificaÃ§Ã£o do Gemini: {display_classification}")
    print("-" * 90)
    print(f"Sentimento Real: {row['sentiment'].capitalize()}")
    print(f"Resultado: {result}")
